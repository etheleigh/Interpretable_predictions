{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YrY1KXAu7xbu"
   },
   "source": [
    "# Recommender System for Board Games from [BoardGameGeek.com](https://boardgamegeek.com/)\n",
    "\n",
    "\n",
    "\n",
    "1.   Iatrou Manos\n",
    "2.   Papageorgiou Vasileios\n",
    "3. Sykianakis Xaralambos\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fG1Bk3RH1Jnm"
   },
   "source": [
    "# Dataset Description\n",
    "\n",
    "\n",
    "\n",
    "*   Games File\n",
    "*   User Ratings File\n",
    "*   Mechanics File\n",
    "*   Themes File\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting alibi\n",
      "  Downloading alibi-0.9.4-py3-none-any.whl (524 kB)\n",
      "     -------------------------------------- 524.2/524.2 kB 3.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests<3.0.0,>=2.21.0 in c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages (from alibi) (2.29.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages (from alibi) (4.5.0)\n",
      "Requirement already satisfied: pandas<3.0.0,>=1.0.0 in c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages (from alibi) (1.5.3)\n",
      "Requirement already satisfied: Pillow<10.0,>=5.4.1 in c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages (from alibi) (9.4.0)\n",
      "Requirement already satisfied: dill<0.4.0,>=0.3.0 in c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages (from alibi) (0.3.6)\n",
      "Collecting scikit-image<0.22,>=0.17.2\n",
      "  Downloading scikit_image-0.21.0-cp310-cp310-win_amd64.whl (22.8 MB)\n",
      "     ---------------------------------------- 22.8/22.8 MB 5.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: matplotlib<4.0.0,>=3.0.0 in c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages (from alibi) (3.7.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.28.1 in c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages (from alibi) (4.65.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.7.0 in c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages (from alibi) (4.29.2)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.16.2 in c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages (from alibi) (1.24.3)\n",
      "Requirement already satisfied: scikit-learn<2.0.0,>=1.0.0 in c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages (from alibi) (1.2.2)\n",
      "Requirement already satisfied: spacy[lookups]<4.0.0,>=2.0.0 in c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages (from alibi) (3.7.2)\n",
      "Requirement already satisfied: blis<0.8.0 in c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages (from alibi) (0.7.11)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.1.0 in c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages (from alibi) (1.10.1)\n",
      "Requirement already satisfied: attrs<24.0.0,>=19.2.0 in c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages (from alibi) (22.1.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages (from matplotlib<4.0.0,>=3.0.0->alibi) (1.0.5)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages (from matplotlib<4.0.0,>=3.0.0->alibi) (1.4.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages (from matplotlib<4.0.0,>=3.0.0->alibi) (4.25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages (from matplotlib<4.0.0,>=3.0.0->alibi) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages (from matplotlib<4.0.0,>=3.0.0->alibi) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages (from matplotlib<4.0.0,>=3.0.0->alibi) (3.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages (from matplotlib<4.0.0,>=3.0.0->alibi) (23.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages (from pandas<3.0.0,>=1.0.0->alibi) (2022.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.21.0->alibi) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.21.0->alibi) (2023.11.17)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.21.0->alibi) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.21.0->alibi) (1.26.15)\n",
      "Requirement already satisfied: networkx>=2.8 in c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages (from scikit-image<0.22,>=0.17.2->alibi) (3.2.1)\n",
      "Requirement already satisfied: imageio>=2.27 in c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages (from scikit-image<0.22,>=0.17.2->alibi) (2.33.1)\n",
      "Collecting PyWavelets>=1.1.1\n",
      "  Downloading pywavelets-1.5.0-cp310-cp310-win_amd64.whl (4.3 MB)\n",
      "     ---------------------------------------- 4.3/4.3 MB 6.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages (from scikit-image<0.22,>=0.17.2->alibi) (2023.12.9)\n",
      "Requirement already satisfied: lazy_loader>=0.2 in c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages (from scikit-image<0.22,>=0.17.2->alibi) (0.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages (from scikit-learn<2.0.0,>=1.0.0->alibi) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages (from scikit-learn<2.0.0,>=1.0.0->alibi) (3.1.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (2.0.10)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (3.0.12)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (3.1.2)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (0.3.4)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (2.4.8)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (2.0.8)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (1.0.5)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (1.10.7)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (3.3.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (65.6.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (3.0.9)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (0.9.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (6.4.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (1.0.10)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (8.2.2)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (1.1.2)\n",
      "Collecting spacy-lookups-data<1.1.0,>=1.0.3\n",
      "  Downloading spacy_lookups_data-1.0.5-py2.py3-none-any.whl (98.5 MB)\n",
      "     ---------------------------------------- 98.5/98.5 MB 5.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.28.1->alibi) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.7.0->alibi) (2022.7.9)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.7.0->alibi) (0.14.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.7.0->alibi) (0.11.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.7.0->alibi) (3.9.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.7.0->alibi) (5.4.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers<5.0.0,>=4.7.0->alibi) (2023.4.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib<4.0.0,>=3.0.0->alibi) (1.16.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy[lookups]<4.0.0,>=2.0.0->alibi) (0.1.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy[lookups]<4.0.0,>=2.0.0->alibi) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy[lookups]<4.0.0,>=2.0.0->alibi) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages (from jinja2->spacy[lookups]<4.0.0,>=2.0.0->alibi) (2.1.1)\n",
      "Installing collected packages: spacy-lookups-data, PyWavelets, scikit-image, alibi\n",
      "  Attempting uninstall: scikit-image\n",
      "    Found existing installation: scikit-image 0.22.0\n",
      "    Uninstalling scikit-image-0.22.0:\n",
      "      Successfully uninstalled scikit-image-0.22.0\n",
      "Successfully installed PyWavelets-1.5.0 alibi-0.9.4 scikit-image-0.21.0 spacy-lookups-data-1.0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\maniat\\appdata\\local\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install alibi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'NumbaDeprecationWarning' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[77], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m, category\u001b[38;5;241m=\u001b[39m\u001b[43mNumbaDeprecationWarning\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'NumbaDeprecationWarning' is not defined"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=NumbaDeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4509,
     "status": "ok",
     "timestamp": 1705326351034,
     "user": {
      "displayName": "Manos Iatrou",
      "userId": "06334887705736778908"
     },
     "user_tz": -60
    },
    "id": "c67SVSui_CC_",
    "outputId": "3e132f4f-b63c-4aa3-ad4d-a63172462e6f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maniat\\AppData\\Local\\anaconda3\\lib\\site-packages\\shap\\utils\\_clustering.py:35: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _pt_shuffle_rec(i, indexes, index_mask, partition_tree, M, pos):\n",
      "C:\\Users\\maniat\\AppData\\Local\\anaconda3\\lib\\site-packages\\shap\\utils\\_clustering.py:54: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def delta_minimization_order(all_masks, max_swap_size=100, num_passes=2):\n",
      "C:\\Users\\maniat\\AppData\\Local\\anaconda3\\lib\\site-packages\\shap\\utils\\_clustering.py:63: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _reverse_window(order, start, length):\n",
      "C:\\Users\\maniat\\AppData\\Local\\anaconda3\\lib\\site-packages\\shap\\utils\\_clustering.py:69: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _reverse_window_score_gain(masks, order, start, length):\n",
      "C:\\Users\\maniat\\AppData\\Local\\anaconda3\\lib\\site-packages\\shap\\utils\\_clustering.py:77: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _mask_delta_score(m1, m2):\n",
      "C:\\Users\\maniat\\AppData\\Local\\anaconda3\\lib\\site-packages\\shap\\links.py:5: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def identity(x):\n",
      "C:\\Users\\maniat\\AppData\\Local\\anaconda3\\lib\\site-packages\\shap\\links.py:10: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _identity_inverse(x):\n",
      "C:\\Users\\maniat\\AppData\\Local\\anaconda3\\lib\\site-packages\\shap\\links.py:15: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def logit(x):\n",
      "C:\\Users\\maniat\\AppData\\Local\\anaconda3\\lib\\site-packages\\shap\\links.py:20: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _logit_inverse(x):\n",
      "C:\\Users\\maniat\\AppData\\Local\\anaconda3\\lib\\site-packages\\shap\\utils\\_masked_model.py:363: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _build_fixed_single_output(averaged_outs, last_outs, outputs, batch_positions, varying_rows, num_varying_rows, link, linearizing_weights):\n",
      "C:\\Users\\maniat\\AppData\\Local\\anaconda3\\lib\\site-packages\\shap\\utils\\_masked_model.py:385: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _build_fixed_multi_output(averaged_outs, last_outs, outputs, batch_positions, varying_rows, num_varying_rows, link, linearizing_weights):\n",
      "C:\\Users\\maniat\\AppData\\Local\\anaconda3\\lib\\site-packages\\shap\\utils\\_masked_model.py:428: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _init_masks(cluster_matrix, M, indices_row_pos, indptr):\n",
      "C:\\Users\\maniat\\AppData\\Local\\anaconda3\\lib\\site-packages\\shap\\utils\\_masked_model.py:439: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _rec_fill_masks(cluster_matrix, indices_row_pos, indptr, indices, M, ind):\n",
      "C:\\Users\\maniat\\AppData\\Local\\anaconda3\\lib\\site-packages\\shap\\maskers\\_tabular.py:186: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _single_delta_mask(dind, masked_inputs, last_mask, data, x, noop_code):\n",
      "C:\\Users\\maniat\\AppData\\Local\\anaconda3\\lib\\site-packages\\shap\\maskers\\_tabular.py:197: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _delta_masking(masks, x, curr_delta_inds, varying_rows_out,\n",
      "C:\\Users\\maniat\\AppData\\Local\\anaconda3\\lib\\site-packages\\shap\\maskers\\_image.py:175: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _jit_build_partition_tree(xmin, xmax, ymin, ymax, zmin, zmax, total_ywidth, total_zwidth, M, clustering, q):\n",
      "C:\\Users\\maniat\\AppData\\Local\\anaconda3\\lib\\site-packages\\shap\\explainers\\_partition.py:676: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def lower_credit(i, value, M, values, clustering):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "\u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import lightgbm\n",
    "from lightgbm import LGBMClassifier\n",
    "from lightgbm.callback import early_stopping, log_evaluation\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import coo_matrix\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.cluster import DBSCAN\n",
    "import umap\n",
    "import optuna\n",
    "from anchor import anchor_tabular\n",
    "from alibi.explainers import AnchorTabular\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\".*colsample_bytree.*\")\n",
    "warnings.filterwarnings(\"ignore\", message=\".*subsample.*\")\n",
    "\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_description(df: pd.DataFrame):\n",
    "    # accepts a dataframe and collapses many one hot encoded columns to \n",
    "    # text with column name if 1\n",
    "    cols = df.columns[15:]\n",
    "    categories = df[cols].gt(0).apply(lambda x: x.index[x].tolist(), axis=1)\n",
    "    \n",
    "    return categories.apply(lambda x: ','.join(x) if x else 'Other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downcasting_types(df: pd.DataFrame):\n",
    "  for column in df.columns:\n",
    "    colType = df[column].dtype\n",
    "    if colType == 'float64' :\n",
    "      df[column] = pd.to_numeric(df[column], downcast='float')\n",
    "    elif colType == 'int64' :\n",
    "      df[column] = pd.to_numeric(df[column], downcast='integer')\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path: str):\n",
    "    \"\"\"\n",
    "    Load all CSV files in the path folder and return a dictionary of DataFrames.\n",
    "\n",
    "    \"\"\"\n",
    "    folder = Path(path)\n",
    "    if not folder.exists() or not folder.is_dir():\n",
    "        raise FileNotFoundError(f\"{path} directory was not found\")\n",
    "\n",
    "    dataframes = {}\n",
    "    for file in folder.glob('*.csv'):\n",
    "        file_name = file.stem\n",
    "        df = pd.read_csv(file)\n",
    "        dataframes[file_name] = df\n",
    "\n",
    "    return dataframes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_merge(dataframes: dict):\n",
    "    \"\"\"\n",
    "    Preprocess and merge DataFrames from the given dictionary\n",
    "    and returns a tuple ,(user_ratings, games_df).\n",
    "    \"\"\"\n",
    "    columns_to_discretize = ['GameWeight', 'MfgPlaytime']\n",
    "    columns_to_keep = ['BGGId', 'GameWeight', 'MfgPlaytime', 'NumAlternates', 'NumExpansions', \n",
    "                               'NumImplementations', 'Kickstarted', 'Cat:Thematic', 'Cat:Strategy', 'Cat:War', \n",
    "                               'Cat:Family', 'Cat:CGS', 'Cat:Abstract', 'Cat:Party', 'Cat:Childrens']\n",
    "    for file_name, df in dataframes.items():\n",
    "        if file_name == \"games\":\n",
    "            # Preprocessing for 'games'\n",
    "            df = df[columns_to_keep].copy()\n",
    "            renaming_dict = {col: col.replace('Cat:', '') if col.startswith('Cat:')\n",
    "                             else col\n",
    "                             for col in df.columns}\n",
    "            df.rename(columns=renaming_dict, inplace=True)\n",
    "            discretizer = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='quantile')\n",
    "            df[columns_to_discretize] = discretizer.fit_transform(df[columns_to_discretize])\n",
    "            \n",
    "            \n",
    "        elif file_name == \"themes\":\n",
    "            # Preprocessing for 'themes'\n",
    "            renaming_dict = {col: col.replace('Theme_', '') if col.startswith('Theme_') \n",
    "                             else col\n",
    "                             for col in df.columns}\n",
    "            df.rename(columns=renaming_dict, inplace=True)\n",
    "        \n",
    "        elif file_name == \"mechanics\":\n",
    "            pass\n",
    "\n",
    "        elif file_name == \"user_ratings\":\n",
    "            \n",
    "            df['Rating'] = df['Rating'].apply(lambda x: 1 if x > 6 else -1)\n",
    "            label_encoder = LabelEncoder()\n",
    "            df['uid'] = label_encoder.fit_transform(df['Username'])\n",
    "            df.drop('Username', axis=1, inplace=True)\n",
    "            df = df.groupby('uid').filter(lambda x: len(x) >= 300).groupby('BGGId').filter(lambda x: len(x) >= 100)\n",
    "            df.drop_duplicates(subset=['uid', 'BGGId'], keep='last', inplace=True)\n",
    "\n",
    "        dataframes[file_name] = df\n",
    "\n",
    "    # Prepare final games dataframe\n",
    "    merged_df = pd.merge(dataframes['games'], dataframes['mechanics'], on='BGGId', how='inner')\n",
    "    games_df = pd.merge(merged_df, dataframes['themes'], on='BGGId', how='inner')\n",
    "    games_df['Details'] = get_description(games_df)\n",
    "    columns_to_drop = dataframes['themes'].columns[1:].tolist() + dataframes['mechanics'].columns[1:].tolist()\n",
    "    games_df = games_df.drop(columns=columns_to_drop, axis=1)\n",
    "    games_df = downcasting_types(games_df) \n",
    "    \n",
    "    \n",
    "    # Prepare final user_ratings dataframe\n",
    "    user_ratings_df = dataframes.get('user_ratings', pd.DataFrame())\n",
    "    user_ratings_df = downcasting_types(user_ratings_df)\n",
    "     \n",
    "\n",
    "    return user_ratings_df, games_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_user_clusters(train_df: pd.DataFrame,\n",
    "                         test_df: pd.DataFrame,\n",
    "                         uid_col: str, #user id col\n",
    "                         gameid_col: str, #game id col\n",
    "                         rating_col: str): #rating col\n",
    "    \"\"\"\n",
    "    Create user clusters for both training and test data\n",
    "    using UMAP for dimensionality reduction and DBSCAN for clustering\n",
    "    and returns a tuple of the clusters for the X_train and X_test\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    #\n",
    "    user_game_matrix_train = train_df.pivot(index=uid_col, columns=gameid_col, values=rating_col).fillna(0)\n",
    "\n",
    "    # UMAP to reduce dimensions on training data\n",
    "    reduction = umap.UMAP(n_neighbors=20, n_components=100, metric='cosine', min_dist=0.0, random_state=42)\n",
    "    embedding_train = reduction.fit_transform(user_game_matrix_train)\n",
    "\n",
    "    # DBSCAN on training data\n",
    "    dbscan = DBSCAN(eps=0.26, min_samples=15, metric='euclidean')\n",
    "    clusters_train = dbscan.fit_predict(embedding_train)\n",
    "    user_game_matrix_train['Cluster'] = clusters_train\n",
    "\n",
    "    # Transform test data using the trained UMAP model\n",
    "    user_game_matrix_test = test_df.pivot(index=uid_col, columns=gameid_col, values=rating_col).fillna(0)\n",
    "    embedding_test = reduction.transform(user_game_matrix_test)\n",
    "    clusters_test = dbscan.fit_predict(embedding_test)\n",
    "    user_game_matrix_test['Cluster'] = clusters_test\n",
    "\n",
    "    return user_game_matrix_train[['Cluster']].reset_index(), user_game_matrix_test[['Cluster']].reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_train_test_split(path: str):\n",
    "    \"\"\"\n",
    "    Loads data, preprocesses it, merges, and returns \n",
    "    the train, test dataframes.\n",
    "    \"\"\"\n",
    "    # Call load_data, preprocess_and_merge\n",
    "    dataframes = load_data(path)\n",
    "    user_ratings_df, games_df = preprocess_and_merge(dataframes)\n",
    "\n",
    "   \n",
    "    X = pd.merge(user_ratings_df, games_df, on='BGGId', how='inner')\n",
    "    y_model = X['Rating'] \n",
    "    X_model = X.drop(['Details'], axis=1)  \n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_model, y_model, test_size=0.20)\n",
    "\n",
    "    train_for_clustering = X_train[['uid', 'BGGId', 'Rating']]\n",
    "    test_for_clustering = X_test[['uid', 'BGGId', 'Rating']]\n",
    "\n",
    "    user_clusters_train, user_clusters_test = create_user_clusters(train_for_clustering, test_for_clustering, 'uid', 'BGGId', 'Rating')\n",
    "\n",
    "    X_train = X_train.merge(user_clusters_train, on='uid', how='left')\n",
    "    X_test = X_test.merge(user_clusters_test, on='uid', how='left')\n",
    "\n",
    "    X_train = X_train.drop(['Rating'], axis=1)\n",
    "    X_test = X_test.drop(['Rating'], axis=1)\n",
    "    y_train = y_train.replace(-1, 0)\n",
    "    y_test = y_test.replace(-1, 0)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_hyperparameters(X_train: pd.DataFrame,\n",
    "                             y_train: pd.DataFrame,\n",
    "                             n_trials: int = 5,\n",
    "                             cv_folds: int = 5):\n",
    "    \"\"\"\n",
    "    Performs hyperparameter optimization using Optuna for LGBMClassifier.\n",
    "    Uses X_train and y_train for n_trials and returns the best \n",
    "    parameters of the optimization.\n",
    "    \"\"\"\n",
    "    \n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    \n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            \"boosting_type\": \"gbdt\",\n",
    "            \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.001, 0.5),\n",
    "            \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.1, 1.0),\n",
    "            \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.1, 1.0),\n",
    "            \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 10),\n",
    "            \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 1, 100)\n",
    "        }\n",
    "\n",
    "       \n",
    "        model = LGBMClassifier(objective='binary',\n",
    "                               metric='binary_logloss',\n",
    "                               **params, n_jobs=-1)\n",
    "\n",
    "        # CV\n",
    "        scores = cross_val_score(model, X_train, y_train,\n",
    "                                 cv=cv_folds, scoring='roc_auc')\n",
    "        return scores.mean()\n",
    "\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "    best_params = study.best_params\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model_with_evaluation(X_train: pd.DataFrame, \n",
    "                                y_train: pd.DataFrame,\n",
    "                                X_test: pd.DataFrame,\n",
    "                                y_test: pd.DataFrame,\n",
    "                                best_params: dict,\n",
    "                                n_estimators: int  # number of boosting rounds for LGBM\n",
    "                               ):\n",
    "    \"\"\"\n",
    "    Trains the model using the best parameters found \n",
    "    by Optuna and evaluates it on the test set and returns the \n",
    "    trained LightGBM model.\n",
    "    \"\"\"\n",
    "    # Create dictionary for params\n",
    "    best_params[\"objective\"] = \"binary\"\n",
    "    best_params[\"metric\"] = \"binary_logloss\"\n",
    "    best_params[\"n_estimators\"] = n_estimators\n",
    "    best_params[\"n_jobs\"] = -1\n",
    "\n",
    "    \n",
    "    model = LGBMClassifier(**best_params)\n",
    "\n",
    "   \n",
    "    early_stopping_callback = early_stopping(stopping_rounds=100, first_metric_only=True, verbose=True)\n",
    "    log_evaluation_callback = log_evaluation(period=50)\n",
    "\n",
    "   \n",
    "    model.fit(X_train, y_train, eval_set=[(X_test, y_test)], callbacks=[early_stopping_callback, log_evaluation_callback])\n",
    "\n",
    "    \n",
    "    y_pred = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    \n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    print(\"ROC AUC on the test set:\", roc_auc)\n",
    "\n",
    "    return model, roc_auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maniat\\AppData\\Local\\anaconda3\\lib\\site-packages\\umap\\umap_.py:1943: UserWarning: n_jobs value -1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(f\"n_jobs value {self.n_jobs} overridden to 1 by setting random_state. Use no seed for parallelism.\")\n"
     ]
    }
   ],
   "source": [
    "folder_path = r'C:\\Users\\maniat\\OneDrive - Lyse AS\\Desktop\\personal\\MSc\\Customer Analytics\\Recommender Classification\\Recommender_Files'\n",
    "X_train, X_test, y_train, y_test = prepare_train_test_split(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-20 00:36:49,292] A new study created in memory with name: no-name-ef01ed6b-d565-4515-bda3-a3713003f2ff\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7790032180615114, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7790032180615114\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.46392871527854584, subsample=1.0 will be ignored. Current value: bagging_fraction=0.46392871527854584\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7790032180615114, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7790032180615114\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.46392871527854584, subsample=1.0 will be ignored. Current value: bagging_fraction=0.46392871527854584\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7790032180615114, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7790032180615114\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.46392871527854584, subsample=1.0 will be ignored. Current value: bagging_fraction=0.46392871527854584\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7790032180615114, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7790032180615114\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.46392871527854584, subsample=1.0 will be ignored. Current value: bagging_fraction=0.46392871527854584\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7790032180615114, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7790032180615114\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.46392871527854584, subsample=1.0 will be ignored. Current value: bagging_fraction=0.46392871527854584\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-20 00:40:19,036] Trial 0 finished with value: 0.7488734072732074 and parameters: {'num_leaves': 135, 'learning_rate': 0.41119433145044537, 'feature_fraction': 0.7790032180615114, 'bagging_fraction': 0.46392871527854584, 'bagging_freq': 6, 'min_child_samples': 32}. Best is trial 0 with value: 0.7488734072732074.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9935014323558218, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9935014323558218\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8524738589877902, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8524738589877902\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9935014323558218, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9935014323558218\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8524738589877902, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8524738589877902\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9935014323558218, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9935014323558218\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8524738589877902, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8524738589877902\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9935014323558218, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9935014323558218\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8524738589877902, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8524738589877902\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9935014323558218, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9935014323558218\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8524738589877902, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8524738589877902\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-20 00:47:05,034] Trial 1 finished with value: 0.744549797163661 and parameters: {'num_leaves': 245, 'learning_rate': 0.06759016136704075, 'feature_fraction': 0.9935014323558218, 'bagging_fraction': 0.8524738589877902, 'bagging_freq': 9, 'min_child_samples': 84}. Best is trial 0 with value: 0.7488734072732074.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7790032180615114, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7790032180615114\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.46392871527854584, subsample=1.0 will be ignored. Current value: bagging_fraction=0.46392871527854584\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's binary_logloss: 0.596069\n",
      "Evaluated only: binary_logloss\n",
      "ROC AUC on the test set: 0.6843827604384857\n"
     ]
    }
   ],
   "source": [
    "opt_params = optimize_hyperparameters(X_train, y_train, n_trials=2)\n",
    "trained_model,roc_auc = train_model_with_evaluation(X_train, y_train, X_test, y_test, best_params = opt_params, n_estimators=10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_game_predict (X_train: pd.DataFrame,\n",
    "                       X_test: pd.DataFrame,\n",
    "                       model # LGBM model\n",
    "                    ): \n",
    "    \n",
    "    column_order = X_train.columns.tolist()\n",
    "    dataset = pd.concat([X_train,X_test])\n",
    "    new_user = dataset.drop_duplicates(subset='uid').loc[:, ['uid', 'Cluster']]\n",
    "    new_game = dataset.drop_duplicates(subset='BGGId').drop(columns=['uid', 'Cluster'])\n",
    "    #pick random user,game\n",
    "    random_user = new_user['uid'].sample(n=1).iloc[0]\n",
    "    random_game = new_game['BGGId'].sample(n=1).iloc[0]\n",
    "    # filter dataframes\n",
    "    selected_user = new_user[new_user['uid'] == random_user]\n",
    "    selected_game = new_game[new_game['BGGId'] == random_game]\n",
    "    test_instance = pd.concat([selected_user.reset_index(drop=True), selected_game.reset_index(drop=True)], axis=1)\n",
    "    test_instance = test_instance[column_order]\n",
    "    predictions = model.predict(test_instance) > 0.5\n",
    "    \n",
    "    # define \n",
    "    def Xplain_predict(X):\n",
    "        return model.predict_proba(X)[:, 1]\n",
    "    # build xplainer\n",
    "    explainer = anchor_tabular.AnchorTabularExplainer(\n",
    "        class_names=['DISLIKE', 'LIKE'],\n",
    "        feature_names=X_train.columns.tolist(),\n",
    "        data=X_train.values,  \n",
    "        categorical_names={}  # Provide dictionary mapping categorical column indices to lists of category names, if any\n",
    "    )\n",
    "    \n",
    "    test_instance = test_instance.values.reshape(1,-1)\n",
    "    explanation = explainer.explain_instance(test_instance[0], lgbm_predict_fn, threshold=0.95)\n",
    "\n",
    "    # Print the explanation details\n",
    "    print('Anchor: %s' % ' AND '.join(explanation.names()))\n",
    "    print('Precision: %.2f' % explanation.precision())\n",
    "    print('Coverage: %.2f' % explanation.coverage())\n",
    "\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find an anchor satisfying the 0.95 precision constraint. Now returning the best non-eligible result. The desired precision threshold might not be achieved due to the quantile-based discretisation of the numerical features. The resolution of the bins may be too large to find an anchor of required precision. Consider increasing the number of bins in `disc_perc`, but note that for some numerical distribution (e.g. skewed distribution) it may not help.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchor: NumExpansions <= 0.00 AND War > 0.00 AND 1.00 < NumAlternates <= 3.00 AND CGS <= 0.00 AND Strategy <= 0.00 AND Party <= 0.00 AND BGGId <= 15878.00 AND 1.00 < GameWeight <= 2.00 AND 1.00 < MfgPlaytime <= 2.00 AND Abstract <= 0.00 AND NumImplementations <= 0.00 AND -1.00 < Cluster <= 0.00 AND uid > 231400.00 AND Family <= 0.00 AND Thematic <= 0.00 AND Kickstarted <= 0.00 AND Childrens <= 0.00\n",
      "Precision: 0.15\n",
      "Coverage: 0.00\n"
     ]
    }
   ],
   "source": [
    "column_order = X_train.columns.tolist()\n",
    "dataset = pd.concat([X_train,X_test])\n",
    "new_user = dataset.drop_duplicates(subset='uid').loc[:, ['uid', 'Cluster']]\n",
    "new_game = dataset.drop_duplicates(subset='BGGId').drop(columns=['uid', 'Cluster'])\n",
    "#pick random user,game\n",
    "random_user = new_user['uid'].sample(n=1).iloc[0]\n",
    "random_game = new_game['BGGId'].sample(n=1).iloc[0]\n",
    "# filter dataframes\n",
    "selected_user = new_user[new_user['uid'] == random_user]\n",
    "selected_game = new_game[new_game['BGGId'] == random_game]\n",
    "test_instance = pd.concat([selected_user.reset_index(drop=True), selected_game.reset_index(drop=True)], axis=1)\n",
    "test_instance = test_instance[column_order]\n",
    "predictions = trained_model.predict(test_instance) > 0.5\n",
    "\n",
    "\n",
    "\n",
    "# Predict function for the Anchor explainer (probability of the positive class)\n",
    "predict_fn = lambda x: trained_model.predict_proba(x)[:, 1]\n",
    "\n",
    "# Initialize the explainer with feature names\n",
    "explainer = AnchorTabular(predict_fn, feature_names=X_train.columns.tolist())\n",
    "\n",
    "explainer.fit(X_train.values)\n",
    "\n",
    "test_instance = test_instance.values.reshape(1, -1)\n",
    "\n",
    "# Generate an explanation\n",
    "explanation = explainer.explain(test_instance, threshold=0.95)\n",
    "\n",
    "# Print the explanation\n",
    "print('Anchor: %s' % (' AND '.join(explanation.anchor)))\n",
    "print('Precision: %.2f' % explanation.precision)\n",
    "print('Coverage: %.2f' % explanation.coverage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
